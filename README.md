# 海量数据处理问题
## 问题描述
假设有一个csv文件，包含40亿条手机号码，号码之间存在重复的情况，请编写一个程序，完成去重。

## 问题分析
经典海量数据处理问题，题目要求内存尽量少，因此除算法选择以外，语言特性对减少内存开销也有帮助。我的主力语言Java运行需要依赖JVM，有额外的内存开销，在我掌握的高级语言中，Go 语言编写的程序运行不依赖虚拟机，虽带有GC但内存开销相对较小，本项目采用 Go 实现，借助 Github copilot 辅助完成。
中国电话号码11位数，算是世界范围内最长的了，假定csv文件中电话号最大为11位，如果存在一个较大的 bitmap, 则将电话号转换为整数类型后，将 bitmap 中该整数对应的位置 bit 设置为1，能简洁高效的表示该整数已存在。因此，讲40亿电话号码遍历处理并存放入 bitmap，再通过 bitmap 存在 1 的bit生成电话号码，能高效的去除重复号码。

## 限制条件
题目硬性规定内存不能超过 1GB，而最大11位的电话号映射到 bitmap 中，预估最多可能占用 10 ^ 11 bit / 8 = 12.5 GB，最少可能占用 10 ^ 10 bit / 8 = 1.25 GB。因此，常规的 bitmap 不可能存放在内存中处理。

### 测试数据集
为了验证算法执行效果，我先编写了 [generate](./generate/generate.go)程序生成4固定长度11位，以1打头的 uint64 随机数据并写入到 [duplicate.csv](./duplicate.csv)文件中，40亿数据文件大小为48GB，程序验证基于此数据集运行。调试时为了快速查看结果，采用了生成40万数据的小数据集，文件大小为4.8MB。

### 运行环境
mbp16 2021款，M1 Pro CPU，32GB RAM

### 方案一  时间换空间
由于现在SSD成本大幅下降，且SSD随机读写性能远好于传统的HDD，因此方案一直接采用SSD代替RAM存放bitmap。我直接通过Go file api中的 ReadAt 和 WriteAt 方法来操作文件中的 byte。因最小操作单位为 byte，因此具体 bit 操作需要自行位运算。例如将 110 电话号码存入文件, 想将文件中第110 bit设置为1，则需要先整除110 / 8 = 13，确定操作文件的第14个字节（下标为13）中的第6（110%8）个bit。\
基于[duplicate.csv](./duplicate.csv)的程序[diskbitmap.go](./diskbitmap/diskbitmap.go)运行得知，生成的 bitmap 文件 duplicate.bin 占用大约 2.5 GB 的磁盘，运行内存开销根据观测大约 10 MB 左右。\
SSD随机读写速度比不上RAM的速度。并且考虑数据分布特性，即使是少量电话号，duplicate.bin 文件依然会存在大量无效空间占用。\
这种方案的优点是内存占用最少，缺点是速度非常慢，bitmap 存在大量浪费，如果有非法数据，极端情况下甚至占满磁盘导致宕机。

### 方案二 分治法 空间换时间
由于 SSD 速度远慢于 RAM, 题目限定内存 1GB 以内，方案二考虑在内存中存储 bitmap，采用分治法将数据集分段处理。这里使用多大的 bitmap 需要权衡。考虑到其他操作对内存的占用以及编程语言底层的内存开销，至少要留出一倍的内存作为 buffer，如果使用 512MB 的 bitmap，程序运行期间很可能超出 1GB 内存限制，因此最大可以选定 256MB 大小的 bitmap 处理。256MB 对应 2 ^ 28 个字节，能存放 2 ^ 31 约为 2 billion 数据。\
[membitmap.go](./membitmap/membitmap.go) 按照此思路实现，首先将数据集分段处理，对每个电话号码以 2^31 整除，按[0, 2^31 - 1], [2^31, 2^31 * 2 -1], [2^31*2, 2^31*3-1] 依此类推的方式分段成文件。注意每处理完一段，手动将bitmap清空，避免依赖GC导致额外分配内存。处理40亿条数据耗时约为30mins，内存占用550MB左右。\
当然如果不追求运行速度，那么可以减少内存占用，将bitmap可以设置更小，切分出更多小文件处理。\
此方案的优点是利用了RAM，处理速度更快,可以灵活定制bitmap大小，在内存和性能之间找到平衡。缺点是需要预处理数据，提前将数据文件分片，磁盘空间开销更大。越小的内存占用对应越多的文件分片数。

## 测试结果
分布在不同大小的数据集下测试，数据集固定为[duplicate.csv](./duplicate.csv)，分布采用4000万，4亿，40亿不同大小的数据集进行测试\
方案一运行方法是在[diskbitmap目录](./diskbitmap/)下执行 go run diskbitmap.go\
方案二运行方法是在[membitmap目录](./membitmap/)下执行 go run membitmap.go，该方案分布在 256MB和4MB\
以上两个程序均可以自行 build 成可执行文件，程序默认读取父目录中的 duplicate.csv 文件，亦可以通过 -input=../xxx.csv 指定输入文件，membitmap程序另外支持设置bitmap大小，通过 -size=xx 可以将 bitmap 大小设置为 2^xx bytes，默认值为22（即为4MB）。为了执行时间更快，推荐将size参数设置为28。

### 4000万数据集
方案一：运行时间 2m6s  最大内存开销 8.1MB\
方案二（256MB bitmap）：运行时间 18s  最大内存开销  543.6MB\
方案二（4MB bitmap）：运行时间 22s  最大内存开销  18.8MB

### 4亿数据集
方案一：运行时间 23m35s 最大内存开销 9.8MB\
方案二（256MB bitmap）：运行时间 2m59s 最大内存开销 562MB\
方案二（4MB bitmap）：运行时间 3m38s  最大内存开销  18.9MB


### 40亿数据集
方案一 运行时间  不详 预计4小时 内存开销10MB\
方案二（256MB bitmap） 运行时间  27m35s  最大内存开销 547MB\
方案二（4MB bitmap）：运行时间 37m33s  最大内存开销  34.5MB

## 总结
在硬件条件允许的情况下，尽量用速度更快的硬件处理问题能省很多时间。
